{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 82852\n",
      "Total male samples: 61025\n",
      "Total female samples: 20957\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = './dataset/'\n",
    "train_data = pd.read_csv(os.path.join(dataset_folder, 'cv-valid-train.csv'))\n",
    "test_data = pd.read_csv(os.path.join(dataset_folder, 'cv-valid-test.csv'))\n",
    "valid_data = pd.read_csv(os.path.join(dataset_folder, 'cv-valid-dev.csv'))\n",
    "\n",
    "n_samples = len(train_data)\n",
    "n_male_samples = len(train_data.loc[train_data['label'] == 'male'])\n",
    "n_female_samples = len(train_data.loc[train_data['label'] == 'female'])\n",
    "print(\"Total samples:\", n_samples)\n",
    "print(\"Total male samples:\", n_male_samples)\n",
    "print(\"Total female samples:\", n_female_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def split_dataframe(df: pd.DataFrame, is_train: bool):\n",
    "    label2int = {\n",
    "        \"male\": 1,\n",
    "        \"female\": 0\n",
    "    }\n",
    "\n",
    "    male = df.loc[df['label'] == 'male']\n",
    "    female = df.loc[df['label'] == 'female']\n",
    "    n_samples_ = min(len(male), len(female))\n",
    "\n",
    "    df = pd.concat([male.sample(n_samples_), female.sample(n_samples_)], ignore_index=True)\\\n",
    "        .sample(frac=1)\\\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    X = df.drop(['label'], axis=1).to_numpy()\n",
    "    y = df['label'].apply(label2int.get).to_numpy()\n",
    "\n",
    "    if is_train:\n",
    "        split_dataframe.scaler.fit(X)\n",
    "\n",
    "    X = split_dataframe.scaler.transform(X)\n",
    "    return X, y\n",
    "\n",
    "split_dataframe.scaler = StandardScaler()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_train, y_train = split_dataframe(train_data, True)\n",
    "X_test, y_test = split_dataframe(test_data, False)\n",
    "X_valid, y_valid = split_dataframe(valid_data, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.811\n",
      "Accuracy on valid set: 0.830\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Accuracy on training set: {tree.score(X_train, y_train):.3f}\")\n",
    "print(f\"Accuracy on test set: {tree.score(X_test, y_test):.3f}\")\n",
    "print(f\"Accuracy on valid set: {tree.score(X_valid, y_valid):.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests\n",
      "Accuracy on training set: 0.983\n",
      "Accuracy on test set: 0.843\n",
      "Accuracy on valid set: 0.854\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0).fit(X_train, y_train)\n",
    "print(\"Random Forests\")\n",
    "print(f\"Accuracy on training set: {forest.score(X_train, y_train):.3f}\")\n",
    "print(f\"Accuracy on test set: {forest.score(X_test, y_test):.3f}\")\n",
    "print(f\"Accuracy on valid set: {forest.score(X_valid, y_valid):.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Accuracy on training set: 0.861\n",
      "Accuracy on test set: 0.852\n",
      "Accuracy on valid set: 0.863\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\n",
    "print(\"Gradient Boosting\")\n",
    "print(f\"Accuracy on training set: {gbrt.score(X_train, y_train):.3f}\")\n",
    "print(f\"Accuracy on test set: {gbrt.score(X_test, y_test):.3f}\")\n",
    "print(f\"Accuracy on valid set: {gbrt.score(X_valid, y_valid):.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "Accuracy on training set: 0.883\n",
      "Accuracy on test set: 0.875\n",
      "Accuracy on valid set: 0.873\n"
     ]
    }
   ],
   "source": [
    "svm = SVC().fit(X_train, y_train)\n",
    "print(\"Support Vector Machine\")\n",
    "print(f\"Accuracy on training set: {svm.score(X_train, y_train):.3f}\")\n",
    "print(f\"Accuracy on test set: {svm.score(X_test, y_test):.3f}\")\n",
    "print(f\"Accuracy on valid set: {svm.score(X_valid, y_valid):.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron\n",
      "Accuracy on training set: 0.899\n",
      "Accuracy on test set: 0.882\n",
      "Accuracy on valid set: 0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallo_dest/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=0).fit(X_train, y_train)\n",
    "print(\"Multilayer Perceptron\")\n",
    "print(f\"Accuracy on training set: {mlp.score(X_train, y_train):.3f}\")\n",
    "print(f\"Accuracy on test set: {mlp.score(X_test, y_test):.3f}\")\n",
    "print(f\"Accuracy on valid set: {mlp.score(X_valid, y_valid):.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}